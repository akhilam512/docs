---
title: "OpenAI (Whisper)"
description: "Speech-to-text service implementation using OpenAIâ€™s Whisper API"
---

## Overview

`OpenAISTTService` provides speech-to-text capabilities using OpenAI's hosted Whisper API. It offers high-accuracy transcription with minimal setup requirements.

## Installation

To use `OpenAISTTService`, install the required dependencies:

```bash
pip install pipecat-ai[openai]
```

You'll need to set up your OpenAI API key as an environment variable: `OPENAI_API_KEY`.

<Tip>
  You can obtain an OpenAI API key from the [OpenAI
  platform](https://platform.openai.com/api-keys).
</Tip>

## Configuration

### Constructor Parameters

<ParamField path="model" type="str" default="whisper-1">
  Whisper model to use. Currently only "whisper-1" is available.
</ParamField>

<ParamField path="api_key" type="str" optional>
  Your OpenAI API key. If not provided, will use environment variable.
</ParamField>

<ParamField path="base_url" type="str" optional>
  Custom API base URL for OpenAI API requests.
</ParamField>

## Input

The service processes audio data with the following requirements:

- PCM audio format
- 16-bit depth
- Single channel (mono)

## Output Frames

The service produces two types of frames during transcription:

### TranscriptionFrame

Generated for final transcriptions, containing:

<ParamField path="text" type="string">
  Transcribed text
</ParamField>

<ParamField path="user_id" type="string">
  User identifier
</ParamField>

<ParamField path="timestamp" type="string">
  ISO 8601 formatted timestamp
</ParamField>

<ParamField path="language" type="Language">
  Detected language (if available)
</ParamField>

### ErrorFrame

Generated when transcription errors occur, containing error details.

## Methods

### Set Model

```python
await service.set_model("whisper-1")
```

See the [STT base class methods](/server/base-classes/speech#methods) for additional functionality.

## Usage Example

```python
from pipecat.services.openai import OpenAISTTService

# Configure service
stt_service = OpenAISTTService(
    model="whisper-1",
    api_key="your-api-key"
)

# Use in pipeline
pipeline = Pipeline([
    transport.input(),
    stt,
    llm,
    ...
])
```

## Frame Flow

```mermaid
graph TD
    A[InputAudioFrame] --> B[OpenAISTTService]
    B --> C[API Request]
    C --> D[TranscriptionFrame]
    B --> E[ErrorFrame]
```

## Metrics Support

The service collects the following metrics:

- Time to First Byte (TTFB)
- Processing duration
- API response time

## Notes

- Requires valid OpenAI API key
- Uses OpenAI's hosted Whisper model
- Handles API rate limiting
- Automatic error handling
- Thread-safe processing

## Error Handling

The service handles common API errors including:

- Authentication errors
- Rate limiting
- Invalid audio format
- Network connectivity issues
- API timeouts

Errors are propagated through ErrorFrames with descriptive messages.
