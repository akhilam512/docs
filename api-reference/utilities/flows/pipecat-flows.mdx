---
title: 'Pipecat Flows'
description: 'Technical reference for Pipecatâ€™s conversation flow system'
---

<Tip>
  New to building conversational flows? Check out our [Pipecat Flows
  guide](/guides/pipecat-flows) first.
</Tip>

## Installation

If you're already using Pipecat:

```bash
pip install pipecat-ai-flows
```

If you're starting fresh:

```bash
# Basic installation
pip install pipecat-ai-flows

# Install Pipecat with required options
# For example, to use OpenAI and Deepgram:
pip install "pipecat-ai[daily,openai,deepgram]"
```

## FlowManager

Main class for managing conversation flows. Handles state transitions, function registration, and action execution.

### Constructor Parameters

<ParamField path="flow_config" type="dict" required>
  Complete flow configuration including initial_node and nodes
</ParamField>

<ParamField path="task" type="PipelineTask" required>
  Pipeline task for frame queueing
</ParamField>

<ParamField path="llm" type="LLMService" required>
  LLM service for handling functions
</ParamField>

<ParamField path="tts" type="TTSService">
  Optional TTS service for immediate speech actions
</ParamField>

### Methods

<ParamField path="initialize" type="async method">
Initialize the flow with starting messages and register edge functions

Parameters:

- initial_messages: List[dict] - Initial context messages

Note: Node functions should be registered with the LLM before calling initialize

</ParamField>

<ParamField path="register_action" type="method">
Register custom action handler

Parameters:

- action_type: str - Action identifier
- handler: Callable - Action handler function

</ParamField>

## Function Types

### Node Functions

Functions that operate within the current node:

- Must NOT match any node names
- Can be called multiple times
- Execute operations without changing state
- Typically handle data operations or API calls

Example:

```python
async def select_value_handler(function_name, tool_call_id, args, llm, context, result_callback):
    value = args["value"]
    await result_callback({"status": "success", "value": value})

# Register node function with LLM
llm.register_function("select_value", select_value_handler)
```

### Edge Functions

Functions that create transitions between nodes:

- Must match the name of an existing node
- Execute once to transition to a new state
- Represent one-way paths in the conversation
- Automatically registered by FlowManager

Edge functions are defined in the flow configuration and don't need explicit handlers.

## Configuration Structure

<ResponseField name="flow_config" type="Object">
  <Expandable title="properties">
    <ResponseField name="initial_node" type="string" required>
      The starting node identifier for the conversation flow
    </ResponseField>

    <ResponseField name="nodes" type="Object" required>
      <Expandable title="properties">
        <ResponseField name="[node_name]" type="Node Object">
          Each key is a node name that can be referenced by Edge Functions

          <Expandable title="properties">
            <ResponseField name="messages" type="Array" required>
              List of messages that set the LLM context. Format depends on the LLM service being used.
              For OpenAI, each message requires 'role' and 'content'.
            </ResponseField>

            <ResponseField name="functions" type="Array" required>
              List of available functions for this node. Can include both Edge Functions (for transitions)
              and Node Functions (for operations within the node). Format depends on the LLM service being used.
              For OpenAI, each function requires 'type', 'function' object with name, description, and parameters.

              Note: Edge Function names MUST match node names to enable transitions.
              Node Function names MUST NOT match any node names.
            </ResponseField>

            <ResponseField name="pre_actions" type="Array">
              Optional actions to execute before LLM context update

              <Expandable title="properties">
                <ResponseField name="type" type="string" required>
                  Action type (e.g., "tts_say")
                </ResponseField>
                <ResponseField name="[parameters]" type="Any">
                  Action-specific parameters
                </ResponseField>
              </Expandable>
            </ResponseField>

            <ResponseField name="post_actions" type="Array">
              Optional actions to execute after LLM context update

              <Expandable title="properties">
                <ResponseField name="type" type="string" required>
                  Action type (e.g., "end_conversation")
                </ResponseField>
                <ResponseField name="[parameters]" type="Any">
                  Action-specific parameters
                </ResponseField>
              </Expandable>
            </ResponseField>
          </Expandable>
        </ResponseField>
      </Expandable>
    </ResponseField>

  </Expandable>
</ResponseField>

## Naming Conventions

While the system is flexible with node naming, we recommend following these conventions:

- **Initial Node**: Use descriptive names (e.g., "greeting", "welcome")
- **End Node**: Use "end" for clarity (recommended but not required)
- **Flow Nodes**: Use purpose-reflecting names (e.g., "get_time", "confirm_order")

These conventions help maintain readable and maintainable flows.

## Example Configuration

Here's a minimal example demonstrating the configuration structure and function types:

```python
flow_config = {
    "initial_node": "greeting",  # Descriptive initial node name
    "nodes": {
        "greeting": {
            "messages": [
                {
                    "role": "system",
                    "content": "Ask if user wants option A or B"
                }
            ],
            "functions": [
                {
                    "type": "function",
                    "function": {
                        "name": "choose_a",  # Edge Function: transitions to choose_a node
                        "description": "User chooses option A",
                        "parameters": {"type": "object", "properties": {}}
                    }
                }
            ]
        },
        "choose_a": {
            "messages": [
                {
                    "role": "system",
                    "content": "Handle option A selection"
                }
            ],
            "functions": [
                {
                    "type": "function",
                    "function": {
                        "name": "select_value",  # Node Function: operates within current node
                        "description": "Select a value",
                        "parameters": {
                            "type": "object",
                            "properties": {
                                "value": {"type": "string"}
                            }
                        }
                    }
                },
                {
                    "type": "function",
                    "function": {
                        "name": "end",  # Edge Function: transitions to end node
                        "description": "Complete the process",
                        "parameters": {"type": "object", "properties": {}}
                    }
                }
            ],
            "pre_actions": [
                {
                    "type": "tts_say",
                    "text": "Processing option A..."
                }
            ]
        },
        "end": {
            "messages": [
                {
                    "role": "system",
                    "content": "Thank the user and end the conversation"
                }
            ],
            "functions": [],
            "post_actions": [
                {
                    "type": "end_conversation"
                }
            ]
        }
    }
}

# Usage Example
llm = OpenAILLMService(api_key=os.getenv("OPENAI_API_KEY"))

# Register node functions first
llm.register_function("select_value", select_value_handler)

# Create flow manager with LLM
flow_manager = FlowManager(flow_config, task, llm, tts)

# Initialize (registers edge functions automatically)
await flow_manager.initialize(messages)
```

## Built-in Actions

<ParamField path="tts_say" type="action">
  Speaks text immediately using TTS service
  <Expandable title="parameters">
    <ResponseField name="text" type="string" required>
      Text to be spoken
    </ResponseField>
  </Expandable>
</ParamField>

<ParamField path="end_conversation" type="action">
  Ends the conversation and closes the connection
  <Expandable title="parameters">
    <ResponseField name="text" type="string">
      Optional farewell message to speak before ending
    </ResponseField>
  </Expandable>
</ParamField>

<Note>
  See the [Pipecat Flows guide](/guides/pipecat-flows) for more complete
  examples and best practices.
</Note>
